{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x244ff32fb90>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0, 1, 0.1), 2*np.arange(0, 1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch import nn, optim\n",
    "import scipy.io as sio\n",
    "# import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "# import readligo as rl\n",
    "# from gwpy.timeseries import TimeSeries\n",
    "import math\n",
    "import random\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('D:\\OneDrive - HKUST Connect\\Research\\GWNMMAD\\Codes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_wsl = 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "rTrain = 0.7;\n",
    "rTest = 0.2;\n",
    "# input_vector_length = 100\n",
    "batch_size = 32\n",
    "num_bins = 40\n",
    "coef_delta = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-AE + WSL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(101, 20),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(20, 101),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(202, 20),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(20, 202),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class WSClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WSClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(101, 32)  # 第一层全连接层，输入维度为4，输出维度为64\n",
    "        self.norm1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()  # 激活函数\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(32, 8)\n",
    "        self.norm2 = nn.BatchNorm1d(8)\n",
    "        self.fc4 = nn.Linear(8, 1)  # 第三层全连接层，输入维度为32，输出维度为类别数目\n",
    "        \n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        nn.init.kaiming_normal_(self.fc4.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm1(self.relu(self.fc1(x)))\n",
    "        x = self.norm2(self.relu(self.fc2(x)))\n",
    "        return self.fc4(x)\n",
    "        # x = self.relu(x)\n",
    "#         x = self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WSClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(101, 32)  # 第一层全连接层，输入维度为4，输出维度为64\n",
    "        self.norm1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()  # 激活函数\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "        # self.norm2 = nn.BatchNorm1d(8)\n",
    "        # self.fc4 = nn.Linear(8, 1)  # 第三层全连接层，输入维度为32，输出维度为类别数目\n",
    "        \n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        # nn.init.kaiming_normal_(self.fc4.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm1(self.relu(self.fc1(x)))\n",
    "        return self.fc2(x)\n",
    "        # x = self.relu(x)\n",
    "#         x = self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WSClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(202, 32)  # 第一层全连接层，输入维度为4，输出维度为64\n",
    "        self.norm1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()  # 激活函数\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "        # self.norm2 = nn.BatchNorm1d(8)\n",
    "        # self.fc4 = nn.Linear(8, 1)  # 第三层全连接层，输入维度为32，输出维度为类别数目\n",
    "        \n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        # nn.init.kaiming_normal_(self.fc4.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm1(self.relu(self.fc1(x)))\n",
    "        return self.fc2(x)\n",
    "        # x = self.relu(x)\n",
    "#         x = self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4161\n"
     ]
    }
   ],
   "source": [
    "ae = AutoEncoder().cuda()\n",
    "print(sum(p.numel() for p in ae.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3361\n"
     ]
    }
   ],
   "source": [
    "wsc = WSClassifier().cuda()\n",
    "print(sum(p.numel() for p in wsc.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WSClassifier(\n",
       "  (fc1): Linear(in_features=101, out_features=32, bias=True)\n",
       "  (norm1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_datatype = [\"noise\", \"bbh\", \"sg\", \"glitch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_wsl_total = 40000;\n",
    "N_wsl = {}\n",
    "N_wsl[\"noise\"] = int(0.75*N_wsl_total)\n",
    "N_wsl[\"bbh\"] = int(0.1*N_wsl_total)\n",
    "N_wsl[\"sg\"] = int(0.1*N_wsl_total)\n",
    "N_wsl[\"glitch\"] = int(0.05*N_wsl_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's try a new scheme, or propotion of data to see its roburtness\n",
    "\n",
    "### What if the test sample is mostly bbh\n",
    "\n",
    "N_wsl_total = 40000;\n",
    "N_wsl = {}\n",
    "N_wsl[\"noise\"] = int(0.1*N_wsl_total)\n",
    "N_wsl[\"bbh\"] = int(0.75*N_wsl_total)\n",
    "N_wsl[\"sg\"] = int(0.1*N_wsl_total)\n",
    "N_wsl[\"glitch\"] = int(0.05*N_wsl_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's try a new scheme, or propotion of data to see its roburtness\n",
    "\n",
    "### What if the test sample is mostly sg\n",
    "\n",
    "N_wsl_total = 40000;\n",
    "N_wsl = {}\n",
    "N_wsl[\"noise\"] = int(0.1*N_wsl_total)\n",
    "N_wsl[\"bbh\"] = int(0.1*N_wsl_total)\n",
    "N_wsl[\"sg\"] = int(0.75*N_wsl_total)\n",
    "N_wsl[\"glitch\"] = int(0.05*N_wsl_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "renorm_factor_0 = 20;\n",
    "renorm_factor_1 = 20;\n",
    "\n",
    "realbkg = np.load('E://GWNMMAD_data/Tw_dataset/Datasets/background.npz')['data'].reshape(-1,200) / renorm_factor_0;\n",
    "realbbh = np.load('E://GWNMMAD_data/Tw_dataset/Datasets/bbh_for_challenge.npy').reshape(-1,200) / renorm_factor_0;\n",
    "\n",
    "realsg = np.load('E://GWNMMAD_data/Tw_dataset/Datasets/sglf_for_challenge.npy').reshape(-1,200) / renorm_factor_0;\n",
    "# realglitch = np.load(\"../data/real_glitches_9998_4000Hz_25ms.npz\")[\"strain_time_data\"]\n",
    "realglitch_L = np.load(\"../Data_cached/real_glitches_snrlt5_60132_4000Hz_25ms.npz\")[\"strain_time_data\"][:50000].reshape(-1,1,200) / renorm_factor_1\n",
    "realglitch_H = np.load('../Data_cached/real_glitches_H_snrlt5_59732_4000Hz_25ms.npz')[\"strain_time_data\"][:50000].reshape(-1,1,200) / renorm_factor_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_first50k = realbkg.reshape(-1,2,200)[:50000]\n",
    "\n",
    "glitch_L_noise_H = np.concatenate((realglitch_L, noise_first50k[:,[1],:]), axis = 1)\n",
    "glitch_H_noise_L = np.concatenate((realglitch_H, noise_first50k[:,[0],:]), axis = 1)\n",
    "realglitch = np.vstack((glitch_L_noise_H, glitch_H_noise_L))\n",
    "np.random.shuffle(realglitch)\n",
    "realglitch = realglitch.reshape(-1,200)\n",
    "realbkg = realbkg[100000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_fft = abs(np.fft.rfft(realbkg))\n",
    "bkg_fft = bkg_fft/np.linalg.norm([bkg_fft], axis=2).T\n",
    "\n",
    "bbh_fft = abs(np.fft.rfft(realbbh))\n",
    "bbh_fft = bbh_fft/np.linalg.norm([bbh_fft], axis=2).T\n",
    "\n",
    "sg_fft = abs(np.fft.rfft(realsg))\n",
    "sg_fft = sg_fft/np.linalg.norm([sg_fft], axis=2).T\n",
    "\n",
    "glitch_fft = abs(np.fft.rfft(realglitch))\n",
    "glitch_fft = glitch_fft/np.linalg.norm([glitch_fft], axis=2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 101)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bkg_fft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 101)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glitch_fft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_fft = bkg_fft.reshape(-1,202)\n",
    "\n",
    "bbh_fft = bbh_fft.reshape(-1,202)\n",
    "\n",
    "sg_fft = sg_fft.reshape(-1,202)\n",
    "\n",
    "glitch_fft = glitch_fft.reshape(-1,202)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_raw = {};\n",
    "dataset_raw[\"noise\"] = np.load(\"E://GWNMMAD_data/Tw_dataset/Datasets/background.npz\")['data'].reshape(-1,200);\n",
    "dataset_raw[\"bbh\"] = np.load(\"E://GWNMMAD_data/Tw_dataset/Datasets/bbh_for_challenge.npy\").reshape(-1,200);\n",
    "dataset_raw[\"sg\"] = np.load(\"E://GWNMMAD_data/Tw_dataset/Datasets/sglf_for_challenge.npy\").reshape(-1,200);\n",
    "# realglitch = np.load(\"../data/real_glitches_9998_4000Hz_25ms.npz\")[\"strain_time_data\"]\n",
    "dataset_raw[\"glitch\"] = np.load(\"../Data_cached/real_glitches_snrlt5_60132_4000Hz_25ms.npz\")[\"strain_time_data\"]\n",
    "\n",
    "dataset_wsl = {};\n",
    "dataset_ae = {};\n",
    "dataset_wsl_fft = {};\n",
    "dataset_ae_fft = {};\n",
    "\n",
    "for dt in list_datatype:\n",
    "    # perm = np.random.permutation(len(dataset_raw[dt]))\n",
    "    perm = np.loadtxt(\"../Data_Cached/SequentialTraining/WSL/perm_\"+dt+\".dat\").astype(int)\n",
    "    nwsl = N_wsl[dt]\n",
    "    dataset_wsl[dt] = dataset_raw[dt][perm[:nwsl]]\n",
    "    dataset_wsl[dt] = dataset_wsl[dt] / np.linalg.norm([dataset_wsl[dt]], axis=2).T\n",
    "    dataset_wsl_fft[dt] = abs(np.fft.rfft(dataset_wsl[dt]))\n",
    "    dataset_wsl_fft[dt] = dataset_wsl_fft[dt]/np.linalg.norm([dataset_wsl_fft[dt]], axis=2).T\n",
    "    \n",
    "    dataset_ae[dt]  = dataset_raw[dt][perm[nwsl:]]\n",
    "    dataset_ae[dt] = dataset_ae[dt] / np.linalg.norm([dataset_ae[dt]], axis=2).T\n",
    "    dataset_ae_fft[dt] = abs(np.fft.rfft(dataset_ae[dt]))\n",
    "    dataset_ae_fft[dt] = dataset_ae_fft[dt]/np.linalg.norm([dataset_ae_fft[dt]], axis=2).T\n",
    "    \n",
    "    # np.savetxt(\"../Data_Cached/SequentialTraining/WSL/perm_\"+dt+\".dat\", perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_raw_fft = {}\n",
    "\n",
    "dataset_raw_fft[\"noise\"] = bkg_fft\n",
    "dataset_raw_fft[\"bbh\"] = bbh_fft\n",
    "dataset_raw_fft[\"sg\"] = sg_fft\n",
    "dataset_raw_fft[\"glitch\"] = glitch_fft\n",
    "\n",
    "dataset_wsl = {};\n",
    "dataset_ae = {};\n",
    "dataset_wsl_fft = {};\n",
    "dataset_ae_fft = {};\n",
    "\n",
    "for dt in list_datatype:\n",
    "    perm = np.random.permutation(len(dataset_raw_fft[dt]))\n",
    "    nwsl = N_wsl[dt]\n",
    "    dataset_wsl_fft[dt] = dataset_raw_fft[dt][perm[:nwsl]]\n",
    "    # dataset_wsl[dt] = dataset_wsl[dt] / np.linalg.norm([dataset_wsl[dt]], axis=2).T\n",
    "    # dataset_wsl_fft[dt] = abs(np.fft.rfft(dataset_wsl[dt]))\n",
    "    # dataset_wsl_fft[dt] = dataset_wsl_fft[dt]/np.linalg.norm([dataset_wsl_fft[dt]], axis=2).T\n",
    "    \n",
    "    dataset_ae_fft[dt]  = dataset_raw_fft[dt][perm[nwsl:]]\n",
    "    # dataset_ae[dt] = dataset_ae[dt] / np.linalg.norm([dataset_ae[dt]], axis=2).T\n",
    "    # dataset_ae_fft[dt] = abs(np.fft.rfft(dataset_ae[dt]))\n",
    "    # dataset_ae_fft[dt] = dataset_ae_fft[dt]/np.linalg.norm([dataset_ae_fft[dt]], axis=2).T\n",
    "    \n",
    "    np.savetxt(\"../Data_Cached/SequentialTraining/WSL/perm_\"+dt+\"_2det.dat\", perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(dataset_ae_fft['noise'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise\n",
      "(20000, 202)\n",
      "bbh\n",
      "(96000, 202)\n",
      "sg\n",
      "(96000, 202)\n",
      "glitch\n",
      "(98000, 202)\n"
     ]
    }
   ],
   "source": [
    "for key in dataset_ae_fft.keys():\n",
    "    print(key)\n",
    "    print(dataset_ae_fft[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise\n",
      "(96000, 101)\n",
      "bbh\n",
      "(70000, 101)\n",
      "sg\n",
      "(96000, 101)\n",
      "glitch\n",
      "(58132, 101)\n"
     ]
    }
   ],
   "source": [
    "for key in dataset_ae_fft.keys():\n",
    "    print(key)\n",
    "    print(dataset_ae_fft[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise\n",
      "(4000, 200)\n",
      "bbh\n",
      "(4000, 200)\n",
      "sg\n",
      "(30000, 200)\n",
      "glitch\n",
      "(2000, 200)\n"
     ]
    }
   ],
   "source": [
    "for key in dataset_wsl.keys():\n",
    "    print(key)\n",
    "    print(dataset_wsl[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"v2\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = [\"glitch\", \"noise\", \"bbh\", \"sg\"];\n",
    "ind2datatype = {};\n",
    "datatype2ind = {};\n",
    "for i, dt in enumerate(sequence):\n",
    "    ind2datatype[i] = dt;\n",
    "    datatype2ind[dt] = i;\n",
    "    \n",
    "torch.save(ind2datatype, \"../Data_cached/SequentialTraining/WSL/sequence_\"+version+\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_wsl_fft_collected = np.empty((0, dataset_wsl_fft[\"glitch\"].shape[1]))\n",
    "for dt in sequence:\n",
    "    dataset_wsl_fft_collected = np.vstack((dataset_wsl_fft_collected, dataset_wsl_fft[dt]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_bkg = len(bkg_reserved_fft);\n",
    "# N_glitch = int(N_bkg/15);\n",
    "# N_bbh = int(N_bkg*2/15);\n",
    "# N_sg = int(N_bkg*2/15);\n",
    "\n",
    "# testset = np.empty((N_bkg+N_glitch+N_bbh+N_sg, len(bkg_reserved_fft[0])))\n",
    "\n",
    "# s = 0;\n",
    "# testset[s : s+N_glitch] = glitch_reserved_fft[np.random.permutation(len(glitch_reserved_fft))[:N_glitch]];\n",
    "# s += N_glitch;\n",
    "\n",
    "# testset[s : s+N_bkg] = bkg_reserved_fft[np.random.permutation(len(bkg_reserved_fft))[:N_bkg]];\n",
    "# s += N_bkg;\n",
    "\n",
    "# testset[s : s+N_bbh] = bbh_reserved_fft[np.random.permutation(len(bbh_reserved_fft))[:N_bbh]];\n",
    "# s += N_bbh;\n",
    "\n",
    "# testset[s : s+N_sg] = sg_reserved_fft[np.random.permutation(len(sg_reserved_fft))[:N_sg]];\n",
    "# s += N_sg;\n",
    "\n",
    "# correct_ans = np.concatenate(([0]*N_glitch, [1]*N_bkg, [2]*N_bbh, [3]*N_sg))\n",
    "\n",
    "# Nsample = {};\n",
    "# Nsample[\"glitch\"] = N_glitch;\n",
    "# Nsample[\"noise\"] = N_bkg;\n",
    "# Nsample[\"bbh\"] = N_bbh;\n",
    "# Nsample[\"sg\"] = N_sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ncut = 5;\n",
    "# cutList = {};\n",
    "\n",
    "# max_glitch = 0.0026;\n",
    "# min_glitch = 0.001;\n",
    "# cutList[\"glitch\"] = np.linspace(min_glitch, max_glitch, Ncut);\n",
    "\n",
    "# max_bkg = 0.0026;\n",
    "# min_bkg = 0.001;\n",
    "# cutList[\"noise\"] = np.linspace(min_bkg, max_bkg, Ncut);\n",
    "\n",
    "# max_bbh = 0.0024;\n",
    "# min_bbh = 0.0008;\n",
    "# cutList[\"bbh\"] = np.linspace(min_bbh, max_bbh, Ncut);\n",
    "\n",
    "# max_sg = 0.003;\n",
    "# min_sg = 0.0003;\n",
    "# cutList[\"sg\"] = np.linspace(min_sg, max_sg, Ncut);\n",
    "\n",
    "# torch.save(cutList, \"../Data_cached/SequentialTraining/WSL/cut_\"+version+\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ncut = 5;\n",
    "cutList = {};\n",
    "\n",
    "max_glitch = 0.0014;\n",
    "min_glitch = 0.0024;\n",
    "cutList[\"glitch\"] = np.linspace(min_glitch, max_glitch, Ncut);\n",
    "\n",
    "max_bkg = 0.0016;\n",
    "min_bkg = 0.0026;\n",
    "cutList[\"noise\"] = np.linspace(min_bkg, max_bkg, Ncut);\n",
    "\n",
    "max_bbh = 0.0014;\n",
    "min_bbh = 0.0024;\n",
    "cutList[\"bbh\"] = np.linspace(min_bbh, max_bbh, Ncut);\n",
    "\n",
    "max_sg = 0.0008;\n",
    "min_sg = 0.0032;\n",
    "cutList[\"sg\"] = np.linspace(min_sg, max_sg, Ncut);\n",
    "\n",
    "torch.save(cutList, \"../Data_cached/SequentialTraining/WSL/cut_\"+version+\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=101, out_features=20, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=101, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models = {};\n",
    "# models[\"glitch\"] = torch.load(\"../Model_cached/4ae_3.pt\")\n",
    "# models[\"glitch\"].cpu().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=202, out_features=20, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=202, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {};\n",
    "models[\"glitch\"] = torch.load(\"../Model_cached/2_det_oneglitchonenoise_trained.pt\")\n",
    "models[\"glitch\"].cpu().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAE(dataset, cutID):\n",
    "    \n",
    "    nTotal = len(dataset);\n",
    "    nTrain = int(rTrain * nTotal)\n",
    "    nTest = int(rTest * nTotal)\n",
    "\n",
    "    X_train = dataset[:nTrain]\n",
    "    X_test = dataset[-nTest:]\n",
    "    X_validation = dataset[nTrain:-nTest]\n",
    "\n",
    "    trainData = torch.FloatTensor(X_train)\n",
    "    testData = torch.FloatTensor(X_test)\n",
    "    validationData = torch.FloatTensor(X_validation)\n",
    "\n",
    "    train_dataset = TensorDataset(trainData)\n",
    "    test_dataset = TensorDataset(testData)\n",
    "    validation_dataset = TensorDataset(validationData)\n",
    "\n",
    "    trainDataLoader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    validationDataLoader = DataLoader(dataset=validation_dataset, batch_size=batch_size, shuffle = True)\n",
    "\n",
    "    autoencoder = AutoEncoder().cuda()\n",
    "    optimizer = optim.Adam(autoencoder.parameters(), lr=0.00005)\n",
    "    loss_func = nn.MSELoss().cuda()\n",
    "    \n",
    "    loss_train = np.empty(epochs)\n",
    "    loss_validation = np.empty(epochs)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        autoencoder.train()\n",
    "        for batchidx, x in enumerate(trainDataLoader):\n",
    "            x = x[0].cuda()\n",
    "            encoded, decoded = autoencoder(x)\n",
    "            loss_overall = loss_func(decoded, x)\n",
    "            weighted_lossTrain = loss_overall\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            weighted_lossTrain.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        autoencoder.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            for batchidx, x in enumerate(validationDataLoader):\n",
    "                x = x[0].cuda()\n",
    "                encoded, decoded = autoencoder(x)\n",
    "                lossVal = loss_func(decoded, x)\n",
    "                val_loss += lossVal.item()\n",
    "\n",
    "            val_loss /= len(validationDataLoader)\n",
    "\n",
    "        loss_train[epoch] = weighted_lossTrain.item()\n",
    "        loss_validation[epoch] = val_loss\n",
    "    \n",
    "    autoencoder.cpu().eval()\n",
    "    _, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    ax[0].plot(loss_train)\n",
    "    ax[0].plot(loss_validation)\n",
    "    \n",
    "    dcd_train = autoencoder(torch.FloatTensor(X_train))[1].detach().numpy()\n",
    "    err_train = np.var(X_train-dcd_train, axis=1)\n",
    "    dcd_test = autoencoder(torch.FloatTensor(X_test))[1].detach().numpy()\n",
    "    err_test = np.var(X_test-dcd_test, axis=1)\n",
    "    foo = ax[1].hist(err_train, range=(0, max(err_train)), bins=50, density=True, histtype=\"step\")\n",
    "    foo = ax[1].hist(err_test, range=(0, max(err_train)), bins=50, density=True, histtype=\"step\")\n",
    "    \n",
    "    plt.savefig(\"../Pic_cached/SequentialTraining/WSL/training_AE_\"+cutID+\"_1.jpg\")\n",
    "    plt.close()\n",
    "            \n",
    "    return autoencoder.cpu().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainWSC(dataset0, dataset1, cutID):\n",
    "# dataset0: bkg set from AE\n",
    "# dataset1: identified signal from AE\n",
    "    \n",
    "    nTotal0, nTotal1 = len(dataset0), len(dataset1);\n",
    "    nTrain0, nTrain1 = int(rTrain * nTotal0), int(rTrain * nTotal1)\n",
    "    nTest0 , nTest1  = int(rTest * nTotal0) , int(rTest * nTotal1)\n",
    "\n",
    "    X_train = np.concatenate((dataset0[:nTrain0], dataset1[:nTrain1]))\n",
    "    X_test = np.concatenate((dataset0[-nTest0:], dataset1[-nTest1:]))\n",
    "    X_validation = np.concatenate((dataset0[nTrain0:-nTest0], dataset1[nTrain1:-nTest1]))\n",
    "    \n",
    "    Y_train = np.concatenate((np.zeros((nTrain0, 1)), np.ones((nTrain1, 1))))\n",
    "    Y_test = np.concatenate((np.zeros((nTest0, 1)), np.ones((nTest1, 1))))\n",
    "    Y_validation = np.concatenate((np.zeros((dataset0[nTrain0:-nTest0].shape[0], 1)), np.ones((dataset1[nTrain1:-nTest1].shape[0], 1))))\n",
    "\n",
    "#     trainData = torch.FloatTensor(X_train)\n",
    "#     testData = torch.FloatTensor(X_test)\n",
    "#     validationData = torch.FloatTensor(X_validation)\n",
    "\n",
    "    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(Y_train))\n",
    "    validation_dataset = TensorDataset(torch.FloatTensor(X_validation), torch.FloatTensor(Y_validation))\n",
    "#     train_dataset = TensorDataset(torch.FloatTensor(X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))), torch.FloatTensor(Y_train.reshape((Y_train.shape[0], 1, Y_train.shape[1]))))\n",
    "#     validation_dataset = TensorDataset(torch.FloatTensor(X_validation.reshape((X_validation.shape[0], 1, X_validation.shape[1]))), torch.FloatTensor(Y_validation.reshape((Y_validation.shape[0], 1, Y_validation.shape[1]))))\n",
    "\n",
    "    trainDataLoader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    validationDataLoader = DataLoader(dataset=validation_dataset, batch_size=batch_size, shuffle = True, drop_last=True)\n",
    "\n",
    "    wsc = WSClassifier().cuda()\n",
    "    optimizer = optim.Adam(wsc.parameters(), lr=0.00005)\n",
    "    loss_func = nn.BCEWithLogitsLoss(pos_weight=torch.FloatTensor([nTrain0/nTrain1])).cuda()\n",
    "    \n",
    "    loss_train = np.empty(epochs)\n",
    "    loss_validation = np.empty(epochs)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "#         t0 = time.time()\n",
    "        wsc.train()\n",
    "        for batchidx, (x, y) in enumerate(trainDataLoader):\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            yprime = wsc(x)\n",
    "            loss = loss_func(yprime, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        wsc.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            for batchidx, (x, y) in enumerate(validationDataLoader):\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "                yprime = wsc(x)\n",
    "                lossVal = loss_func(yprime, y)\n",
    "                val_loss += lossVal.item()\n",
    "\n",
    "            val_loss /= len(validationDataLoader)\n",
    "\n",
    "        loss_train[epoch] = loss.item()\n",
    "        loss_validation[epoch] = val_loss\n",
    "#         print(time.time() - t0)\n",
    "        \n",
    "    wsc.cpu().eval()\n",
    "    \n",
    "    _, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    ax[0].plot(loss_train)\n",
    "    ax[0].plot(loss_validation)\n",
    "    foo = ax[1].hist(nn.Sigmoid()(wsc(torch.FloatTensor(X_train))).detach().numpy().flatten(), range=(0, 1), bins=20, density=True, histtype=\"step\")\n",
    "    foo = ax[1].hist(nn.Sigmoid()(wsc(torch.FloatTensor(X_test ))).detach().numpy().flatten(), range=(0, 1), bins=20, density=True, histtype=\"step\")\n",
    "    \n",
    "    plt.savefig(\"../Pic_cached/SequentialTraining/WSL/training_WSC_\"+cutID+\"_1.jpg\")\n",
    "    plt.close()\n",
    "    \n",
    "    return wsc.cpu().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model1 \u001b[38;5;241m=\u001b[39m trainWSC(\u001b[43mdataset0\u001b[49m, dataset1, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39meval();\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset0' is not defined"
     ]
    }
   ],
   "source": [
    "model1 = trainWSC(dataset0, dataset1, \"test\").cpu().eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnt = 0;\n",
    "\n",
    "ic = np.zeros(4, dtype=\"int\")\n",
    "\n",
    "# loop for only the cut in glitch, noise and bbh as it's not really meaningful to set cut in sg w/o new signals\n",
    "ic[3] = Ncut-1;\n",
    "\n",
    "# listResult = {};\n",
    "# listResult[\"cut\"] = np.empty((Ncut**(len(list_datatype)-1), len(list_datatype)), dtype=\"int\");\n",
    "# listResult[\"ans\"] = np.empty((Ncut**(len(list_datatype)-1), len(testset)), dtype=\"int\");\n",
    "# listResult[\"accuracy_4\"] = np.empty((Ncut**(len(list_datatype)-1), len(list_datatype)))\n",
    "# listResult[\"accuracy_2\"] = np.empty((Ncut**(len(list_datatype)-1), 2))\n",
    "\n",
    "for ic[0], ic[1], ic[2] in itertools.product(np.arange(Ncut), np.arange(Ncut), np.arange(Ncut)):\n",
    "# for ic[0], ic[1], ic[2], ic[3] in itertools.product(np.arange(Ncut), np.arange(Ncut), np.arange(Ncut), np.arange(Ncut)):\n",
    "    cnt += 1;\n",
    "    \n",
    "    if cnt < 83:\n",
    "        continue\n",
    "    elif cnt > 84:\n",
    "        continue\n",
    "    \n",
    "    t0 = time.time()\n",
    "    data_filtered = {};\n",
    "    for dt in sequence:\n",
    "        data_filtered[dt] = dataset_ae_fft[dt]\n",
    "#     data_filtered[\"noise\"] = bkg_fft;\n",
    "#     data_filtered[\"bbh\"] = bbh_fft;\n",
    "#     data_filtered[\"sg\"] = sg_fft;\n",
    "\n",
    "    dataset_wsl_filtered = dataset_wsl_fft_collected\n",
    "    \n",
    "    cutID = \"\".join(str(ic[j]) for j in range(3)) + \"_\"+version\n",
    "        \n",
    "    for iPrev in range(3):\n",
    "        previousStep = ind2datatype[iPrev];\n",
    "        modelPrev = models[previousStep]; # previous step AE\n",
    "        \n",
    "        # train the WSC according to previous AE's cut\n",
    "        \n",
    "        dataset0 = data_filtered[previousStep] # here they haven't been updated yet\n",
    "        \n",
    "        dcd = modelPrev(torch.FloatTensor(dataset0))[1].detach().numpy();\n",
    "        dataset1 = dataset0[np.var(dataset0-dcd, axis=1) >= cutList[previousStep][ic[iPrev]]]\n",
    "        \n",
    "        dcd = modelPrev(torch.FloatTensor(dataset_wsl_filtered))[1].detach().numpy();\n",
    "        dataset1 = dataset_wsl_filtered[np.var(dataset_wsl_filtered-dcd, axis=1) >= cutList[previousStep][ic[iPrev]]]\n",
    "        \n",
    "        model = trainWSC(dataset0, dataset1, cutID)\n",
    "        models[previousStep+\"_WSC\"] = model;\n",
    "        \n",
    "        # filter the data according to previous WSC\n",
    "        for j in range(iPrev, 4):\n",
    "            dt = ind2datatype[j];\n",
    "            dcd = nn.Sigmoid()(model(torch.FloatTensor(data_filtered[dt]))).detach().numpy().flatten();\n",
    "            data_filtered[dt] = data_filtered[dt][dcd>0.5]\n",
    "        \n",
    "#         # filter the data\n",
    "#         for j in range(iPrev+1, 4):\n",
    "#             dt = ind2datatype[j];\n",
    "#             dcd = modelPrev(torch.FloatTensor(data_filtered[dt]))[1].detach().numpy()\n",
    "#             data_filtered[dt] = data_filtered[dt][np.var(data_filtered[dt]-dcd, axis=1) >= cutList[previousStep][ic[iPrev]]]            \n",
    "        \n",
    "        # train the current step AE\n",
    "        currentStep = ind2datatype[iPrev+1];\n",
    "        model = trainAE(data_filtered[currentStep], cutID);\n",
    "        models[currentStep] = model;\n",
    "        \n",
    "    torch.save(models, \"../Data_cached/SequentialTraining/WSL/trained_model\" + \"\".join(str(ic[j]) for j in range(3)) + \"_\"+version+\".json\")\n",
    "    print(models.keys())\n",
    "    \n",
    "#     dcd = {};\n",
    "#     err = {};\n",
    "#     ans = np.zeros(len(testset), dtype=\"int\")\n",
    "    \n",
    "#     for datatype in list_datatype:\n",
    "#         dcd[datatype] = models[datatype](torch.FloatTensor(testset))[1].detach().numpy()\n",
    "#         err[datatype] = np.var(testset-dcd[datatype], axis=1)\n",
    "        \n",
    "#     not_select = np.array([True]*len(testset));\n",
    "\n",
    "#     for iStep in range(len(list_datatype)):\n",
    "#         datatype = ind2datatype[iStep];\n",
    "#         ind_pass = np.logical_and(not_select, err[datatype] <= cutList[datatype][ic[iStep]]);\n",
    "#         ans[ind_pass] = iStep;\n",
    "#         not_select[ind_pass] = False;\n",
    "        \n",
    "#     ans[not_select] = -1;\n",
    "    \n",
    "#     listResult[\"cut\"][cnt] = ic;\n",
    "#     listResult[\"ans\"][cnt] = ans;\n",
    "    \n",
    "#     acc = np.zeros(len(ind2datatype));\n",
    "    \n",
    "#     for i in range(len(ind2datatype)):\n",
    "#         acc[i] = np.sum(np.logical_and(ans==i, correct_ans==i))/Nsample[ind2datatype[i]];\n",
    "        \n",
    "#     listResult[\"accuracy_4\"][cnt] = acc;\n",
    "    \n",
    "#     listResult[\"accuracy_2\"][cnt] = [ np.sum(acc[datatype2ind[dtype]]*Nsample[dtype] for dtype in [\"glitch\", \"noise\"])/np.sum(Nsample[dtype] for dtype in [\"glitch\", \"noise\"]), \n",
    "#                                      np.sum(acc[datatype2ind[dtype]]*Nsample[dtype] for dtype in [\"bbh\", \"sg\"])/np.sum(Nsample[dtype] for dtype in [\"bbh\", \"sg\"])]\n",
    "    \n",
    "    \n",
    "    print(cnt)\n",
    "    print(time.time() - t0)\n",
    "    \n",
    "# listResult[\"total_accuracy\"] = np.sum(listResult[\"ans\"]==correct_ans, axis=1)/len(testset);\n",
    "# torch.save(listResult, \"../data/SequentialTraining/training_performance_\"+version+\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = dataset_wsl_fft_collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 101)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_ans = np.hstack(([0]*N_wsl['glitch'], [1]*N_wsl['noise'], [2]*N_wsl['bbh'], [3]*N_wsl['sg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_ans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liyang Miao\\AppData\\Local\\Temp\\ipykernel_11852\\1107368471.py:97: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  listResult[\"accuracy_2\"][cnt] = [ np.sum(acc[datatype2ind[dtype]]*N_wsl[dtype] for dtype in [\"glitch\", \"noise\"])/np.sum(N_wsl[dtype] for dtype in [\"glitch\", \"noise\"]),\n",
      "C:\\Users\\Liyang Miao\\AppData\\Local\\Temp\\ipykernel_11852\\1107368471.py:98: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  np.sum(acc[datatype2ind[dtype]]*N_wsl[dtype] for dtype in [\"bbh\", \"sg\"])/np.sum(N_wsl[dtype] for dtype in [\"bbh\", \"sg\"])]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data_cached/SequentialTraining/WSL/trained_model313_v5.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 64\u001b[0m\n\u001b[0;32m     25\u001b[0m     cutID \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(ic[j]) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mversion\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#     for iPrev in range(3):\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#         previousStep = ind2datatype[iPrev];\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#         modelPrev = models[previousStep]; # previous step AE\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m#     torch.save(models, \"../Data_cached/SequentialTraining/WSL/trained_model\" + \"\".join(str(ic[j]) for j in range(3)) + \"_\"+version+\".json\")\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m#     print(models.keys())\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m     models \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../Data_cached/SequentialTraining/WSL/trained_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mic\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m     dcd \u001b[38;5;241m=\u001b[39m {};\n\u001b[0;32m     67\u001b[0m     err \u001b[38;5;241m=\u001b[39m {};\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data_cached/SequentialTraining/WSL/trained_model313_v5.json'"
     ]
    }
   ],
   "source": [
    "listResult = {};\n",
    "listResult[\"cut\"] = np.empty((Ncut**(len(list_datatype)-1), len(list_datatype)), dtype=\"int\");\n",
    "listResult[\"ans\"] = np.empty((Ncut**(len(list_datatype)-1), len(testset)), dtype=\"int\");\n",
    "listResult[\"accuracy_4\"] = np.empty((Ncut**(len(list_datatype)-1), len(list_datatype)))\n",
    "listResult[\"accuracy_2\"] = np.empty((Ncut**(len(list_datatype)-1), 2))\n",
    "cnt = 0\n",
    "\n",
    "\n",
    "for ic[0], ic[1], ic[2] in itertools.product(np.arange(Ncut), np.arange(Ncut), np.arange(Ncut)):\n",
    "\n",
    "    \n",
    "    # if cnt < 86:\n",
    "    #     continue\n",
    "    \n",
    "    t0 = time.time()\n",
    "    data_filtered = {};\n",
    "    for dt in sequence:\n",
    "        data_filtered[dt] = dataset_ae_fft[dt]\n",
    "#     data_filtered[\"noise\"] = bkg_fft;\n",
    "#     data_filtered[\"bbh\"] = bbh_fft;\n",
    "#     data_filtered[\"sg\"] = sg_fft;\n",
    "\n",
    "    dataset_wsl_filtered = dataset_wsl_fft_collected\n",
    "    \n",
    "    cutID = \"\".join(str(ic[j]) for j in range(3)) + \"_\"+version\n",
    "        \n",
    "#     for iPrev in range(3):\n",
    "#         previousStep = ind2datatype[iPrev];\n",
    "#         modelPrev = models[previousStep]; # previous step AE\n",
    "        \n",
    "#         # train the WSC according to previous AE's cut\n",
    "        \n",
    "#         dataset0 = data_filtered[previousStep] # here they haven't been updated yet\n",
    "        \n",
    "#         dcd = modelPrev(torch.FloatTensor(dataset0))[1].detach().numpy();\n",
    "#         dataset1 = dataset0[np.var(dataset0-dcd, axis=1) >= cutList[previousStep][ic[iPrev]]]\n",
    "        \n",
    "#         dcd = modelPrev(torch.FloatTensor(dataset_wsl_filtered))[1].detach().numpy();\n",
    "#         dataset1 = dataset_wsl_filtered[np.var(dataset_wsl_filtered-dcd, axis=1) >= cutList[previousStep][ic[iPrev]]]\n",
    "        \n",
    "#         model = trainWSC(dataset0, dataset1, cutID)\n",
    "#         models[previousStep+\"_WSC\"] = model;\n",
    "        \n",
    "#         # filter the data according to previous WSC\n",
    "#         for j in range(iPrev, 4):\n",
    "#             dt = ind2datatype[j];\n",
    "#             dcd = nn.Sigmoid()(model(torch.FloatTensor(data_filtered[dt]))).detach().numpy().flatten();\n",
    "#             data_filtered[dt] = data_filtered[dt][dcd>0.5]\n",
    "        \n",
    "# #         # filter the data\n",
    "# #         for j in range(iPrev+1, 4):\n",
    "# #             dt = ind2datatype[j];\n",
    "# #             dcd = modelPrev(torch.FloatTensor(data_filtered[dt]))[1].detach().numpy()\n",
    "# #             data_filtered[dt] = data_filtered[dt][np.var(data_filtered[dt]-dcd, axis=1) >= cutList[previousStep][ic[iPrev]]]            \n",
    "        \n",
    "#         # train the current step AE\n",
    "#         currentStep = ind2datatype[iPrev+1];\n",
    "#         model = trainAE(data_filtered[currentStep], cutID);\n",
    "#         models[currentStep] = model;\n",
    "        \n",
    "#     torch.save(models, \"../Data_cached/SequentialTraining/WSL/trained_model\" + \"\".join(str(ic[j]) for j in range(3)) + \"_\"+version+\".json\")\n",
    "#     print(models.keys())\n",
    "    \n",
    "    models = torch.load(\"../Data_cached/SequentialTraining/WSL/trained_model\" + \"\".join(str(ic[j]) for j in range(3)) + \"_\"+version+\".json\")\n",
    "    \n",
    "    dcd = {};\n",
    "    err = {};\n",
    "    ans = np.zeros(len(testset), dtype=\"int\")\n",
    "    \n",
    "    for datatype in list_datatype:\n",
    "        if datatype == 'sg':\n",
    "            dcd[datatype] = models[datatype](torch.FloatTensor(testset))[1].detach().numpy()\n",
    "        else:\n",
    "            dcd[datatype] = models[datatype + \"_WSC\"](torch.FloatTensor(testset))[1].detach().numpy()\n",
    "        err[datatype] = np.var(testset-dcd[datatype], axis=1)\n",
    "        \n",
    "    not_select = np.array([True]*len(testset));\n",
    "\n",
    "    for iStep in range(len(list_datatype)):\n",
    "        datatype = ind2datatype[iStep];\n",
    "        ind_pass = np.logical_and(not_select, err[datatype] <= cutList[datatype][ic[iStep]]);\n",
    "        ans[ind_pass] = iStep;\n",
    "        not_select[ind_pass] = False;\n",
    "        \n",
    "    ans[not_select] = -1;\n",
    "    \n",
    "    listResult[\"cut\"][cnt] = ic;\n",
    "    listResult[\"ans\"][cnt] = ans;\n",
    "    \n",
    "    acc = np.zeros(len(ind2datatype));\n",
    "    \n",
    "    for i in range(len(ind2datatype)):\n",
    "        acc[i] = np.sum(np.logical_and(ans==i, correct_ans==i))/N_wsl[ind2datatype[i]];\n",
    "        \n",
    "    listResult[\"accuracy_4\"][cnt] = acc;\n",
    "    \n",
    "    listResult[\"accuracy_2\"][cnt] = [ np.sum(acc[datatype2ind[dtype]]*N_wsl[dtype] for dtype in [\"glitch\", \"noise\"])/np.sum(N_wsl[dtype] for dtype in [\"glitch\", \"noise\"]), \n",
    "                                     np.sum(acc[datatype2ind[dtype]]*N_wsl[dtype] for dtype in [\"bbh\", \"sg\"])/np.sum(N_wsl[dtype] for dtype in [\"bbh\", \"sg\"])]\n",
    "\n",
    "    cnt += 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'glitch': array([0.0024 , 0.00215, 0.0019 , 0.00165, 0.0014 ]),\n",
       " 'noise': array([0.0026 , 0.00235, 0.0021 , 0.00185, 0.0016 ]),\n",
       " 'bbh': array([0.0024 , 0.00215, 0.0019 , 0.00165, 0.0014 ]),\n",
       " 'sg': array([0.0032, 0.0026, 0.002 , 0.0014, 0.0008])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[83]], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(np.all(np.array(list(itertools.product(np.arange(Ncut), np.arange(Ncut), np.arange(Ncut)))) == np.array([3,1,3]), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(itertools.product(np.arange(Ncut), np.arange(Ncut), np.arange(Ncut))))[69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 4])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'glitch': array([0.001 , 0.0014, 0.0018, 0.0022, 0.0026]),\n",
       " 'noise': array([0.001 , 0.0014, 0.0018, 0.0022, 0.0026]),\n",
       " 'bbh': array([0.0008, 0.0012, 0.0016, 0.002 , 0.0024]),\n",
       " 'sg': array([0.0003  , 0.000975, 0.00165 , 0.002325, 0.003   ])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noise', 'bbh', 'sg', 'glitch']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Liyang Miao\\AppData\\Local\\Temp\\ipykernel_30640\\149171650.py:48: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  listResult[\"accuracy_2\"][cnt] = [ np.sum(acc[datatype2ind[dtype]]*N_wsl[dtype] for dtype in [\"glitch\", \"noise\"])/np.sum(N_wsl[dtype] for dtype in [\"glitch\", \"noise\"]),\n",
      "C:\\Users\\Liyang Miao\\AppData\\Local\\Temp\\ipykernel_30640\\149171650.py:49: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  np.sum(acc[datatype2ind[dtype]]*N_wsl[dtype] for dtype in [\"bbh\", \"sg\"])/np.sum(N_wsl[dtype] for dtype in [\"bbh\", \"sg\"])]\n"
     ]
    }
   ],
   "source": [
    "listResult = {};\n",
    "listResult[\"cut\"] = np.empty((Ncut**(len(list_datatype)-1), len(list_datatype)), dtype=\"int\");\n",
    "listResult[\"ans\"] = np.empty((Ncut**(len(list_datatype)-1), len(testset)), dtype=\"int\");\n",
    "listResult[\"accuracy_4\"] = np.empty((Ncut**(len(list_datatype)-1), len(list_datatype)))\n",
    "listResult[\"accuracy_2\"] = np.empty((Ncut**(len(list_datatype)-1), 2))\n",
    "\n",
    "\n",
    "models = torch.load(\"../Data_cached/SequentialTraining/WSL/trained_model234\" + \"_\"+version+\".json\")\n",
    "\n",
    "ic = [2,3,4,4]\n",
    "\n",
    "cnt = 69\n",
    " \n",
    "dcd = {};\n",
    "err = {};\n",
    "ans = np.zeros(len(testset), dtype=\"int\")\n",
    "\n",
    "for datatype in list_datatype:\n",
    "    if datatype == 'sg':\n",
    "        dcd[datatype] = models[datatype](torch.FloatTensor(testset))[1].detach().numpy()\n",
    "        err[datatype] = np.var(testset-dcd[datatype], axis=1)\n",
    "    else:\n",
    "        dcd[datatype] = nn.Sigmoid()(models[datatype + \"_WSC\"](torch.FloatTensor(testset))).detach().numpy().reshape(-1)\n",
    "    \n",
    "not_select = np.array([True]*len(testset));\n",
    "\n",
    "for iStep in range(len(list_datatype)):\n",
    "    datatype = ind2datatype[iStep];\n",
    "    if datatype == 'sg':\n",
    "        ind_pass = np.logical_and(not_select, err[datatype] <= cutList[datatype][ic[iStep]]);\n",
    "    else:\n",
    "        ind_pass = np.logical_and(not_select, dcd[datatype] <= 0.5);\n",
    "    ans[ind_pass] = iStep;\n",
    "    not_select[ind_pass] = False;\n",
    "    \n",
    "ans[not_select] = -1;\n",
    "\n",
    "listResult[\"cut\"][cnt] = ic;\n",
    "listResult[\"ans\"][cnt] = ans;\n",
    "\n",
    "acc = np.zeros(len(ind2datatype));\n",
    "\n",
    "for i in range(len(ind2datatype)):\n",
    "    acc[i] = np.sum(np.logical_and(ans==i, correct_ans==i))/N_wsl[ind2datatype[i]];\n",
    "    \n",
    "listResult[\"accuracy_4\"][cnt] = acc;\n",
    "\n",
    "listResult[\"accuracy_2\"][cnt] = [ np.sum(acc[datatype2ind[dtype]]*N_wsl[dtype] for dtype in [\"glitch\", \"noise\"])/np.sum(N_wsl[dtype] for dtype in [\"glitch\", \"noise\"]), \n",
    "                                    np.sum(acc[datatype2ind[dtype]]*N_wsl[dtype] for dtype in [\"bbh\", \"sg\"])/np.sum(N_wsl[dtype] for dtype in [\"bbh\", \"sg\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.977 , 0.976 , 0.7806, 0.6305])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listResult['accuracy_4'][69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.977     , 0.976     , 0.7955    , 0.62236667])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Below is the result for 0.75 sg\n",
    "listResult['accuracy_4'][69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sg': array([0.00451602, 0.0025333 , 0.00160951, ..., 0.00090683, 0.00214158,\n",
       "        0.00206059])}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'noise': array([0.9999442 , 0.9796825 , 0.9128403 , ..., 0.6633201 , 0.46464553,\n",
       "        0.2889956 ], dtype=float32),\n",
       " 'bbh': array([0.9999831 , 0.98511606, 0.82954043, ..., 0.99999917, 0.00114036,\n",
       "        0.23513603], dtype=float32),\n",
       " 'sg': array([[0.03459989, 0.04457035, 0.09483806, ..., 0.00964832, 0.00899084,\n",
       "         0.00922357],\n",
       "        [0.02848431, 0.04531   , 0.09156237, ..., 0.00825534, 0.00780367,\n",
       "         0.008074  ],\n",
       "        [0.02812543, 0.04217976, 0.08721285, ..., 0.00721938, 0.00685893,\n",
       "         0.0073244 ],\n",
       "        ...,\n",
       "        [0.02270237, 0.030991  , 0.06366357, ..., 0.00560454, 0.00527439,\n",
       "         0.00541654],\n",
       "        [0.02963375, 0.04724742, 0.09873857, ..., 0.00735726, 0.00794172,\n",
       "         0.00793119],\n",
       "        [0.02629772, 0.04116438, 0.09110257, ..., 0.00663446, 0.00791417,\n",
       "         0.00724479]], dtype=float32),\n",
       " 'glitch': array([0.00441079, 0.02439942, 0.03001123, ..., 0.99699676, 0.99909115,\n",
       "        0.9998821 ], dtype=float32)}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0272, 0.0478, 0.0733,  ..., 0.0042, 0.0047, 0.0049],\n",
       "        [0.0253, 0.0410, 0.1282,  ..., 0.0057, 0.0052, 0.0062],\n",
       "        [0.0330, 0.0573, 0.1352,  ..., 0.0056, 0.0054, 0.0050],\n",
       "        ...,\n",
       "        [0.0284, 0.0611, 0.1066,  ..., 0.0055, 0.0046, 0.0048],\n",
       "        [0.0322, 0.0510, 0.0856,  ..., 0.0059, 0.0054, 0.0042],\n",
       "        [0.0241, 0.0474, 0.1303,  ..., 0.0049, 0.0056, 0.0051]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['glitch'](torch.FloatTensor(testset))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40000, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[\"glitch_WSC\"](torch.FloatTensor(testset)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02439942], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Sigmoid()(models[\"glitch_WSC\"](torch.FloatTensor(testset))[1]).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0003  , 0.000975, 0.00165 , 0.002325, 0.003   ])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutList['sg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(ans[-4000:] == -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18671, 1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(ans[10000:] == 3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 1)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(ans == -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
