{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2082fa323d0>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0, 1, 0.1), 2*np.arange(0, 1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch import nn, optim\n",
    "import scipy.io as sio\n",
    "# import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "# import readligo as rl\n",
    "# from gwpy.timeseries import TimeSeries\n",
    "import math\n",
    "import random\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:\\OneDrive - HKUST Connect\\Research\\GWNMMAD\\Codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_wsl = 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "rTrain = 0.7;\n",
    "rTest = 0.2;\n",
    "# input_vector_length = 100\n",
    "batch_size = 32\n",
    "num_bins = 40\n",
    "coef_delta = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-AE + WSL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(101, 20),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(20, 101),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class WSClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WSClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(101, 32)  # 第一层全连接层，输入维度为4，输出维度为64\n",
    "        self.norm1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()  # 激活函数\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(32, 8)\n",
    "        self.norm2 = nn.BatchNorm1d(8)\n",
    "        self.fc4 = nn.Linear(8, 1)  # 第三层全连接层，输入维度为32，输出维度为类别数目\n",
    "        \n",
    "        nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight)\n",
    "        nn.init.kaiming_normal_(self.fc4.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm1(self.relu(self.fc1(x)))\n",
    "        x = self.norm2(self.relu(self.fc2(x)))\n",
    "        return self.fc4(x)\n",
    "        # x = self.relu(x)\n",
    "#         x = self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4161\n"
     ]
    }
   ],
   "source": [
    "ae = AutoEncoder().cuda()\n",
    "print(sum(p.numel() for p in ae.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3617\n"
     ]
    }
   ],
   "source": [
    "wsc = WSClassifier().cuda()\n",
    "print(sum(p.numel() for p in wsc.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_datatype = [\"noise\", \"bbh\", \"sg\", \"glitch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_wsl_total = 40000;\n",
    "N_wsl = {}\n",
    "N_wsl[\"noise\"] = int(0.75*N_wsl_total)\n",
    "N_wsl[\"bbh\"] = int(0.1*N_wsl_total)\n",
    "N_wsl[\"sg\"] = int(0.1*N_wsl_total)\n",
    "N_wsl[\"glitch\"] = int(0.05*N_wsl_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_raw = {};\n",
    "dataset_raw[\"noise\"] = np.load(\"E://GWNMMAD_data/Tw_dataset/Datasets/background.npz\")['data'][:, 0];\n",
    "dataset_raw[\"bbh\"] = np.load(\"E://GWNMMAD_data/Tw_dataset/Datasets/bbh_for_challenge.npy\")[:, 0];\n",
    "dataset_raw[\"sg\"] = np.load(\"E://GWNMMAD_data/Tw_dataset/Datasets/sglf_for_challenge.npy\")[:, 0];\n",
    "# realglitch = np.load(\"../data/real_glitches_9998_4000Hz_25ms.npz\")[\"strain_time_data\"]\n",
    "dataset_raw[\"glitch\"] = np.load(\"../Data_cached/real_glitches_snrlt5_60132_4000Hz_25ms.npz\")[\"strain_time_data\"]\n",
    "\n",
    "dataset_wsl = {};\n",
    "dataset_ae = {};\n",
    "dataset_wsl_fft = {};\n",
    "dataset_ae_fft = {};\n",
    "\n",
    "for dt in list_datatype:\n",
    "    perm = np.random.permutation(len(dataset_raw[dt]))\n",
    "    nwsl = N_wsl[dt]\n",
    "    dataset_wsl[dt] = dataset_raw[dt][perm[:nwsl]]\n",
    "    dataset_wsl[dt] = dataset_wsl[dt] / np.linalg.norm([dataset_wsl[dt]], axis=2).T\n",
    "    dataset_wsl_fft[dt] = abs(np.fft.rfft(dataset_wsl[dt]))\n",
    "    dataset_wsl_fft[dt] = dataset_wsl_fft[dt]/np.linalg.norm([dataset_wsl_fft[dt]], axis=2).T\n",
    "    \n",
    "    dataset_ae[dt]  = dataset_raw[dt][perm[nwsl:]]\n",
    "    dataset_ae[dt] = dataset_ae[dt] / np.linalg.norm([dataset_ae[dt]], axis=2).T\n",
    "    dataset_ae_fft[dt] = abs(np.fft.rfft(dataset_ae[dt]))\n",
    "    dataset_ae_fft[dt] = dataset_ae_fft[dt]/np.linalg.norm([dataset_ae_fft[dt]], axis=2).T\n",
    "    \n",
    "    np.savetxt(\"../Data_cached/SequentialTraining/WSL/perm_\"+dt+\".dat\", perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise\n",
      "(70000, 101)\n",
      "bbh\n",
      "(96000, 101)\n",
      "sg\n",
      "(96000, 101)\n",
      "glitch\n",
      "(58132, 101)\n"
     ]
    }
   ],
   "source": [
    "for key in dataset_ae_fft.keys():\n",
    "    print(key)\n",
    "    print(dataset_ae_fft[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise\n",
      "(30000, 200)\n",
      "bbh\n",
      "(4000, 200)\n",
      "sg\n",
      "(4000, 200)\n",
      "glitch\n",
      "(2000, 200)\n"
     ]
    }
   ],
   "source": [
    "for key in dataset_wsl.keys():\n",
    "    print(key)\n",
    "    print(dataset_wsl[key].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"v1\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = [\"glitch\", \"noise\", \"bbh\", \"sg\"];\n",
    "ind2datatype = {};\n",
    "datatype2ind = {};\n",
    "for i, dt in enumerate(sequence):\n",
    "    ind2datatype[i] = dt;\n",
    "    datatype2ind[dt] = i;\n",
    "    \n",
    "torch.save(ind2datatype, \"../Data_cached/SequentialTraining/WSL/sequence_\"+version+\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_wsl_fft_collected = np.empty((0, dataset_wsl_fft[\"glitch\"].shape[1]))\n",
    "for dt in sequence:\n",
    "    dataset_wsl_fft_collected = np.vstack((dataset_wsl_fft_collected, dataset_wsl_fft[dt]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_bkg = len(bkg_reserved_fft);\n",
    "# N_glitch = int(N_bkg/15);\n",
    "# N_bbh = int(N_bkg*2/15);\n",
    "# N_sg = int(N_bkg*2/15);\n",
    "\n",
    "# testset = np.empty((N_bkg+N_glitch+N_bbh+N_sg, len(bkg_reserved_fft[0])))\n",
    "\n",
    "# s = 0;\n",
    "# testset[s : s+N_glitch] = glitch_reserved_fft[np.random.permutation(len(glitch_reserved_fft))[:N_glitch]];\n",
    "# s += N_glitch;\n",
    "\n",
    "# testset[s : s+N_bkg] = bkg_reserved_fft[np.random.permutation(len(bkg_reserved_fft))[:N_bkg]];\n",
    "# s += N_bkg;\n",
    "\n",
    "# testset[s : s+N_bbh] = bbh_reserved_fft[np.random.permutation(len(bbh_reserved_fft))[:N_bbh]];\n",
    "# s += N_bbh;\n",
    "\n",
    "# testset[s : s+N_sg] = sg_reserved_fft[np.random.permutation(len(sg_reserved_fft))[:N_sg]];\n",
    "# s += N_sg;\n",
    "\n",
    "# correct_ans = np.concatenate(([0]*N_glitch, [1]*N_bkg, [2]*N_bbh, [3]*N_sg))\n",
    "\n",
    "# Nsample = {};\n",
    "# Nsample[\"glitch\"] = N_glitch;\n",
    "# Nsample[\"noise\"] = N_bkg;\n",
    "# Nsample[\"bbh\"] = N_bbh;\n",
    "# Nsample[\"sg\"] = N_sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ncut = 5;\n",
    "cutList = {};\n",
    "\n",
    "max_glitch = 0.0026;\n",
    "min_glitch = 0.001;\n",
    "cutList[\"glitch\"] = np.linspace(min_glitch, max_glitch, Ncut);\n",
    "\n",
    "max_bkg = 0.0026;\n",
    "min_bkg = 0.001;\n",
    "cutList[\"noise\"] = np.linspace(min_bkg, max_bkg, Ncut);\n",
    "\n",
    "max_bbh = 0.0024;\n",
    "min_bbh = 0.0008;\n",
    "cutList[\"bbh\"] = np.linspace(min_bbh, max_bbh, Ncut);\n",
    "\n",
    "max_sg = 0.003;\n",
    "min_sg = 0.0003;\n",
    "cutList[\"sg\"] = np.linspace(min_sg, max_sg, Ncut);\n",
    "\n",
    "torch.save(cutList, \"../Data_cached/SequentialTraining/WSL/cut_\"+version+\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=101, out_features=20, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=101, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {};\n",
    "models[\"glitch\"] = torch.load(\"../Model_cached/4ae_3.pt\")\n",
    "models[\"glitch\"].cpu().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAE(dataset, cutID):\n",
    "    \n",
    "    nTotal = len(dataset);\n",
    "    nTrain = int(rTrain * nTotal)\n",
    "    nTest = int(rTest * nTotal)\n",
    "\n",
    "    X_train = dataset[:nTrain]\n",
    "    X_test = dataset[-nTest:]\n",
    "    X_validation = dataset[nTrain:-nTest]\n",
    "\n",
    "    trainData = torch.FloatTensor(X_train)\n",
    "    testData = torch.FloatTensor(X_test)\n",
    "    validationData = torch.FloatTensor(X_validation)\n",
    "\n",
    "    train_dataset = TensorDataset(trainData)\n",
    "    test_dataset = TensorDataset(testData)\n",
    "    validation_dataset = TensorDataset(validationData)\n",
    "\n",
    "    trainDataLoader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    validationDataLoader = DataLoader(dataset=validation_dataset, batch_size=batch_size, shuffle = True)\n",
    "\n",
    "    autoencoder = AutoEncoder().cuda()\n",
    "    optimizer = optim.Adam(autoencoder.parameters(), lr=0.00005)\n",
    "    loss_func = nn.MSELoss().cuda()\n",
    "    \n",
    "    loss_train = np.empty(epochs)\n",
    "    loss_validation = np.empty(epochs)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        autoencoder.train()\n",
    "        for batchidx, x in enumerate(trainDataLoader):\n",
    "            x = x[0].cuda()\n",
    "            encoded, decoded = autoencoder(x)\n",
    "            loss_overall = loss_func(decoded, x)\n",
    "            weighted_lossTrain = loss_overall\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            weighted_lossTrain.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        autoencoder.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            for batchidx, x in enumerate(validationDataLoader):\n",
    "                x = x[0].cuda()\n",
    "                encoded, decoded = autoencoder(x)\n",
    "                lossVal = loss_func(decoded, x)\n",
    "                val_loss += lossVal.item()\n",
    "\n",
    "            val_loss /= len(validationDataLoader)\n",
    "\n",
    "        loss_train[epoch] = weighted_lossTrain.item()\n",
    "        loss_validation[epoch] = val_loss\n",
    "    \n",
    "    autoencoder.cpu().eval()\n",
    "    _, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    ax[0].plot(loss_train)\n",
    "    ax[0].plot(loss_validation)\n",
    "    \n",
    "    dcd_train = autoencoder(torch.FloatTensor(X_train))[1].detach().numpy()\n",
    "    err_train = np.var(X_train-dcd_train, axis=1)\n",
    "    dcd_test = autoencoder(torch.FloatTensor(X_test))[1].detach().numpy()\n",
    "    err_test = np.var(X_test-dcd_test, axis=1)\n",
    "    foo = ax[1].hist(err_train, range=(0, max(err_train)), bins=50, density=True, histtype=\"step\")\n",
    "    foo = ax[1].hist(err_test, range=(0, max(err_train)), bins=50, density=True, histtype=\"step\")\n",
    "    \n",
    "    plt.savefig(\"../Pic_cached/SequentialTraining/WSL/training_AE_\"+cutID+\".jpg\")\n",
    "    plt.close()\n",
    "            \n",
    "    return autoencoder.cpu().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainWSC(dataset0, dataset1, cutID):\n",
    "# dataset0: bkg set from AE\n",
    "# dataset1: identified signal from AE\n",
    "    \n",
    "    nTotal0, nTotal1 = len(dataset0), len(dataset1);\n",
    "    nTrain0, nTrain1 = int(rTrain * nTotal0), int(rTrain * nTotal1)\n",
    "    nTest0 , nTest1  = int(rTest * nTotal0) , int(rTest * nTotal1)\n",
    "\n",
    "    X_train = np.concatenate((dataset0[:nTrain0], dataset1[:nTrain1]))\n",
    "    X_test = np.concatenate((dataset0[-nTest0:], dataset1[-nTest1:]))\n",
    "    X_validation = np.concatenate((dataset0[nTrain0:-nTest0], dataset1[nTrain1:-nTest1]))\n",
    "    \n",
    "    Y_train = np.concatenate((np.zeros((nTrain0, 1)), np.ones((nTrain1, 1))))\n",
    "    Y_test = np.concatenate((np.zeros((nTest0, 1)), np.ones((nTest1, 1))))\n",
    "    Y_validation = np.concatenate((np.zeros((dataset0[nTrain0:-nTest0].shape[0], 1)), np.ones((dataset1[nTrain1:-nTest1].shape[0], 1))))\n",
    "\n",
    "#     trainData = torch.FloatTensor(X_train)\n",
    "#     testData = torch.FloatTensor(X_test)\n",
    "#     validationData = torch.FloatTensor(X_validation)\n",
    "\n",
    "    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(Y_train))\n",
    "    validation_dataset = TensorDataset(torch.FloatTensor(X_validation), torch.FloatTensor(Y_validation))\n",
    "#     train_dataset = TensorDataset(torch.FloatTensor(X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))), torch.FloatTensor(Y_train.reshape((Y_train.shape[0], 1, Y_train.shape[1]))))\n",
    "#     validation_dataset = TensorDataset(torch.FloatTensor(X_validation.reshape((X_validation.shape[0], 1, X_validation.shape[1]))), torch.FloatTensor(Y_validation.reshape((Y_validation.shape[0], 1, Y_validation.shape[1]))))\n",
    "\n",
    "    trainDataLoader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    validationDataLoader = DataLoader(dataset=validation_dataset, batch_size=batch_size, shuffle = True, drop_last=True)\n",
    "\n",
    "    wsc = WSClassifier().cuda()\n",
    "    optimizer = optim.Adam(wsc.parameters(), lr=0.00005)\n",
    "    loss_func = nn.BCEWithLogitsLoss(pos_weight=torch.FloatTensor([nTrain0/nTrain1])).cuda()\n",
    "    \n",
    "    loss_train = np.empty(epochs)\n",
    "    loss_validation = np.empty(epochs)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "#         t0 = time.time()\n",
    "        wsc.train()\n",
    "        for batchidx, (x, y) in enumerate(trainDataLoader):\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            yprime = wsc(x)\n",
    "            loss = loss_func(yprime, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        wsc.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            for batchidx, (x, y) in enumerate(validationDataLoader):\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "                yprime = wsc(x)\n",
    "                lossVal = loss_func(yprime, y)\n",
    "                val_loss += lossVal.item()\n",
    "\n",
    "            val_loss /= len(validationDataLoader)\n",
    "\n",
    "        loss_train[epoch] = loss.item()\n",
    "        loss_validation[epoch] = val_loss\n",
    "#         print(time.time() - t0)\n",
    "        \n",
    "    wsc.cpu().eval()\n",
    "    \n",
    "    _, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    ax[0].plot(loss_train)\n",
    "    ax[0].plot(loss_validation)\n",
    "    foo = ax[1].hist(nn.Sigmoid()(wsc(torch.FloatTensor(X_train))).detach().numpy().flatten(), range=(0, 1), bins=20, density=True, histtype=\"step\")\n",
    "    foo = ax[1].hist(nn.Sigmoid()(wsc(torch.FloatTensor(X_test ))).detach().numpy().flatten(), range=(0, 1), bins=20, density=True, histtype=\"step\")\n",
    "    \n",
    "    plt.savefig(\"../Pic_cached/SequentialTraining/WSL/training_WSC_\"+cutID+\".jpg\")\n",
    "    plt.close()\n",
    "    \n",
    "    return wsc.cpu().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model1 \u001b[38;5;241m=\u001b[39m trainWSC(\u001b[43mdataset0\u001b[49m, dataset1, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39meval();\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset0' is not defined"
     ]
    }
   ],
   "source": [
    "model1 = trainWSC(dataset0, dataset1, \"test\").cpu().eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "86\n",
      "1350.0373215675354\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "87\n",
      "1240.647240638733\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "88\n",
      "1104.9463024139404\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "89\n",
      "1071.8743631839752\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "90\n",
      "4897.44998550415\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "91\n",
      "7820.235460281372\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "92\n",
      "7173.524542331696\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "93\n",
      "6424.977255582809\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "94\n",
      "1102.740933418274\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "95\n",
      "943.111809015274\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "96\n",
      "1106.3638999462128\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "97\n",
      "978.5776615142822\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "98\n",
      "914.3785698413849\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "99\n",
      "822.6703569889069\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "100\n",
      "759.0509495735168\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "101\n",
      "1138.887704372406\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "102\n",
      "1149.1119766235352\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "103\n",
      "1180.441704750061\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "104\n",
      "1108.3617470264435\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "105\n",
      "1030.1703841686249\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "106\n",
      "1497.6204175949097\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "107\n",
      "1432.5199806690216\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "108\n",
      "1268.4540359973907\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "109\n",
      "1150.0282871723175\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "110\n",
      "1135.823745727539\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "111\n",
      "1301.4917318820953\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "112\n",
      "1206.8585708141327\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "113\n",
      "1076.2681365013123\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "114\n",
      "1022.4987087249756\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "115\n",
      "943.656329870224\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "116\n",
      "1088.3152661323547\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "117\n",
      "1005.907523393631\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "118\n",
      "985.7336881160736\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "119\n",
      "863.4846348762512\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "120\n",
      "870.8209893703461\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "121\n",
      "920.6127119064331\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "122\n",
      "913.9125607013702\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "123\n",
      "918.0723738670349\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "124\n",
      "845.6912183761597\n",
      "dict_keys(['glitch', 'glitch_WSC', 'noise', 'noise_WSC', 'bbh', 'bbh_WSC', 'sg'])\n",
      "125\n",
      "872.9014036655426\n"
     ]
    }
   ],
   "source": [
    "cnt = 0;\n",
    "\n",
    "ic = np.zeros(4, dtype=\"int\")\n",
    "\n",
    "# loop for only the cut in glitch, noise and bbh as it's not really meaningful to set cut in sg w/o new signals\n",
    "ic[3] = Ncut-1;\n",
    "\n",
    "# listResult = {};\n",
    "# listResult[\"cut\"] = np.empty((Ncut**(len(list_datatype)-1), len(list_datatype)), dtype=\"int\");\n",
    "# listResult[\"ans\"] = np.empty((Ncut**(len(list_datatype)-1), len(testset)), dtype=\"int\");\n",
    "# listResult[\"accuracy_4\"] = np.empty((Ncut**(len(list_datatype)-1), len(list_datatype)))\n",
    "# listResult[\"accuracy_2\"] = np.empty((Ncut**(len(list_datatype)-1), 2))\n",
    "\n",
    "for ic[0], ic[1], ic[2] in itertools.product(np.arange(Ncut), np.arange(Ncut), np.arange(Ncut)):\n",
    "# for ic[0], ic[1], ic[2], ic[3] in itertools.product(np.arange(Ncut), np.arange(Ncut), np.arange(Ncut), np.arange(Ncut)):\n",
    "    cnt += 1;\n",
    "\n",
    "    if cnt < 86:\n",
    "        continue\n",
    "\n",
    "    t0 = time.time()\n",
    "    data_filtered = {};\n",
    "    for dt in sequence:\n",
    "        data_filtered[dt] = dataset_ae_fft[dt]\n",
    "#     data_filtered[\"noise\"] = bkg_fft;\n",
    "#     data_filtered[\"bbh\"] = bbh_fft;\n",
    "#     data_filtered[\"sg\"] = sg_fft;\n",
    "\n",
    "    dataset_wsl_filtered = dataset_wsl_fft_collected\n",
    "    \n",
    "    cutID = \"\".join(str(ic[j]) for j in range(3)) + \"_\"+version\n",
    "        \n",
    "    for iPrev in range(3):\n",
    "        previousStep = ind2datatype[iPrev];\n",
    "        modelPrev = models[previousStep]; # previous step AE\n",
    "        \n",
    "        # train the WSC according to previous AE's cut\n",
    "        \n",
    "        dataset0 = data_filtered[previousStep] # here they haven't been updated yet\n",
    "        \n",
    "        dcd = modelPrev(torch.FloatTensor(dataset0))[1].detach().numpy();\n",
    "        dataset1 = dataset0[np.var(dataset0-dcd, axis=1) >= cutList[previousStep][ic[iPrev]]]\n",
    "        \n",
    "        dcd = modelPrev(torch.FloatTensor(dataset_wsl_filtered))[1].detach().numpy();\n",
    "        dataset1 = np.vstack((dataset1, dataset_wsl_filtered[np.var(dataset_wsl_filtered-dcd, axis=1) >= cutList[previousStep][ic[iPrev]]]));\n",
    "        \n",
    "        model = trainWSC(dataset0, dataset1, cutID)\n",
    "        models[previousStep+\"_WSC\"] = model;\n",
    "        \n",
    "        # filter the data according to previous WSC\n",
    "        for j in range(iPrev, 4):\n",
    "            dt = ind2datatype[j];\n",
    "            dcd = nn.Sigmoid()(model(torch.FloatTensor(data_filtered[dt]))).detach().numpy().flatten();\n",
    "            data_filtered[dt] = data_filtered[dt][dcd>0.5]\n",
    "        \n",
    "#         # filter the data\n",
    "#         for j in range(iPrev+1, 4):\n",
    "#             dt = ind2datatype[j];\n",
    "#             dcd = modelPrev(torch.FloatTensor(data_filtered[dt]))[1].detach().numpy()\n",
    "#             data_filtered[dt] = data_filtered[dt][np.var(data_filtered[dt]-dcd, axis=1) >= cutList[previousStep][ic[iPrev]]]            \n",
    "        \n",
    "        # train the current step AE\n",
    "        currentStep = ind2datatype[iPrev+1];\n",
    "        model = trainAE(data_filtered[currentStep], cutID);\n",
    "        models[currentStep] = model;\n",
    "        \n",
    "    torch.save(models, \"../Data_cached/SequentialTraining/WSL/trained_model\" + \"\".join(str(ic[j]) for j in range(3)) + \"_\"+version+\".json\")\n",
    "    print(models.keys())\n",
    "    \n",
    "#     dcd = {};\n",
    "#     err = {};\n",
    "#     ans = np.zeros(len(testset), dtype=\"int\")\n",
    "    \n",
    "#     for datatype in list_datatype:\n",
    "#         dcd[datatype] = models[datatype](torch.FloatTensor(testset))[1].detach().numpy()\n",
    "#         err[datatype] = np.var(testset-dcd[datatype], axis=1)\n",
    "        \n",
    "#     not_select = np.array([True]*len(testset));\n",
    "\n",
    "#     for iStep in range(len(list_datatype)):\n",
    "#         datatype = ind2datatype[iStep];\n",
    "#         ind_pass = np.logical_and(not_select, err[datatype] <= cutList[datatype][ic[iStep]]);\n",
    "#         ans[ind_pass] = iStep;\n",
    "#         not_select[ind_pass] = False;\n",
    "        \n",
    "#     ans[not_select] = -1;\n",
    "    \n",
    "#     listResult[\"cut\"][cnt] = ic;\n",
    "#     listResult[\"ans\"][cnt] = ans;\n",
    "    \n",
    "#     acc = np.zeros(len(ind2datatype));\n",
    "    \n",
    "#     for i in range(len(ind2datatype)):\n",
    "#         acc[i] = np.sum(np.logical_and(ans==i, correct_ans==i))/Nsample[ind2datatype[i]];\n",
    "        \n",
    "#     listResult[\"accuracy_4\"][cnt] = acc;\n",
    "    \n",
    "#     listResult[\"accuracy_2\"][cnt] = [ np.sum(acc[datatype2ind[dtype]]*Nsample[dtype] for dtype in [\"glitch\", \"noise\"])/np.sum(Nsample[dtype] for dtype in [\"glitch\", \"noise\"]), \n",
    "#                                      np.sum(acc[datatype2ind[dtype]]*Nsample[dtype] for dtype in [\"bbh\", \"sg\"])/np.sum(Nsample[dtype] for dtype in [\"bbh\", \"sg\"])]\n",
    "    \n",
    "    \n",
    "    print(cnt)\n",
    "    print(time.time() - t0)\n",
    "    \n",
    "# listResult[\"total_accuracy\"] = np.sum(listResult[\"ans\"]==correct_ans, axis=1)/len(testset);\n",
    "# torch.save(listResult, \"../data/SequentialTraining/training_performance_\"+version+\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
